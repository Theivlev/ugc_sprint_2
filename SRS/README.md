# **Система сбора и обработки пользовательских действий**

## **Описание проекта**
Этот проект предназначен для сбора данных о действиях пользователей через API, их обработки с помощью ETL-сервиса и хранения в ClickHouse. Система обеспечивает высокую производительность, надёжность и масштабируемость, а также поддерживает безопасность и мониторинг.

---

## **Функциональные требования**

### **1. API для сбора пользовательских действий**
API предоставляет интерфейс для сбора данных о действиях пользователей. Основные функции:

- **Приём данных**:
  - Принимать данные о действиях пользователей (Время, тип действия, идентификатор пользователя).
  - Поддерживать разные форматы входящих данных.

- **Безопасность**:
  - Обеспечивать возможность авторизации или аутентификации для безопасности (OAuth 2.0).

- **Логирование**:
  - Логировать запросы и сохранять метаданные (IP-адрес клиента, время обработки запроса).

- **Интеграция с Kafka**:
  - Отправлять данные в Kafka в виде сообщений.

---

### **2. ETL-сервис для переноса данных**
ETL-сервис отвечает за обработку данных из Kafka и их запись в ClickHouse. Основные функции:

- **Чтение данных**:
  - Читать сообщения из Kafka.
  - Парсить и проверять данные на корректность перед записью.

- **Запись данных**:
  - Записывать данные в ClickHouse.

- **Обработка ошибок**:
  - Обрабатывать ошибки чтения или записи.
  - Предоставлять возможность автоматического повтора чтения сообщений при сбоях.

- **Конфигурация**:
  - Поддерживать конфигурацию для работы с несколькими топиками и таблицами.

---

## **Нефункциональные требования**

### **1. Производительность**
- **API**:
  - RPS (Requests Per Second): API должно обрабатывать до **1000 запросов в секунду**.
  - Время отклика: API должно возвращать ответ клиенту не более чем за **200 мс**.

- **Kafka и ETL-сервис**:
  - Kafka и ETL-сервис должны поддерживать пиковую нагрузку до **5000 сообщений в секунду**.

---

### **2. Надёжность**
- Гарантия доставки данных в Kafka.
- Обработка отказов в ETL-сервисе (автоматический повтор чтения сообщений при сбоях).

---

### **3. Масштабируемость**
- Возможность горизонтального масштабирования API.
- Kafka настроена на несколько брокеров для распределённой обработки сообщений.

---

### **4. Хранилище**
- **Объём данных в ClickHouse**:
  - Ожидается **2.5 миллионов событий в день** (размер одного события **4 KB**).
  - Ежедневный объём данных: ~**2.5 GB**.
  - Годовой объём данных: ~**2 TB**.

---

### **5. Управляемость и мониторинг**
- Метрики запросов и ошибок доступны через **Prometheus/Grafana**.
- Логи API и ETL доступны централизованно через **ELK-стек** или аналогичные системы.

---

### **6. Безопасность**
- Использование **HTTPS** для API.
- Авторизация доступа с помощью ключей или токенов (например, **OAuth 2.0**).
- Шифрование данных в **Kafka** и **ClickHouse**.

---

## **Архитектура системы**

### **1. Компоненты системы**
- **API**: Сбор данных о действиях пользователей.
- **Kafka**: Брокер сообщений для временного хранения данных.
- **ETL-сервис**: Обработка данных из Kafka и запись в ClickHouse.
- **ClickHouse**: Хранилище данных для аналитики.

### **2. Поток данных**
1. Пользовательские действия отправляются через API.
2. API логирует запросы и отправляет данные в Kafka.
3. ETL-сервис читает данные из Kafka, проверяет их корректность и записывает в ClickHouse.
4. Мониторинг и логи доступны через Prometheus/Grafana и ELK-стек.

---

## **Требования к окружению**

### **1. Инструменты и технологии**
- **Язык программирования**: Python.
- **Брокер сообщений**: Rabbitmq, Apache Kafka.
- **Хранилище данных**: Postgres, ClickHouse.
- **Мониторинг**: Prometheus, Grafana.
- **Логи**: ELK-стек (Elasticsearch, Logstash, Kibana).

### **2. Инфраструктура**
- Серверы для размещения API, Kafka, ETL-сервиса и ClickHouse.
- Настройка SSL/TLS для HTTPS.
- Настройка шифрования данных в Kafka и ClickHouse.
